import re
import requests
from urllib.parse import urlparse

def find_emails(url):
    try:
        # Send an HTTP request to fetch the webpage content
        response = requests.get(url)
        response.raise_for_status()  # Raise an exception for HTTP errors
        if response.status_code == 200:
            # Use regular expressions to find email addresses
            emails = re.findall(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', response.text)
            return emails
        else:
            print(f"Failed to retrieve the webpage. HTTP Status Code: {response.status_code}")
            return []
    except requests.exceptions.RequestException as e:
        print(f"An error occurred while fetching the webpage: {e}")
        return []

if __name__ == "__main__":
    try:
        webpage_url = input("Enter the URL of the webpage to search: ").strip()
        # Check if the URL is valid
        parsed_url = urlparse(webpage_url)
        if parsed_url.scheme not in ['http', 'https']:
            raise ValueError("Invalid URL. Only HTTP and HTTPS URLs are supported.")
        
        found_emails = find_emails(webpage_url)
        if found_emails:
            print("Found email addresses:")
            for email in found_emails:
                print(email)
        else:
            print("No email addresses found.")
    except Exception as e:
        print(f"An error occurred: {e}")

